input {
 # beat에서 데이터를 받을 logstash의 port지정
  beats {
    port => 5044  # filebeat.yml 191번째와 포트번호 맞춰서 연결시켜줌
  }
}

filter {
  mutate {
    # 실제 데이터는 "message" 필드로 오기 때문에 csv형태의 내용을 분할하여 새로운 이름으로 필드를 추가 
    split => [ "message",  "," ] 
    add_field => {
      "year" => "%{[message][0]}"
      "net_subg" => "%{[message][1]}"
      "net_reveg" => "%{[message][2]}"
      "movie_reveg" => "%{[message][3]}"
      "audience_g" => "%{[message][4]}"
      
    }

    # 기본으로 전송되는 데이터 분석에 불필요한 필드 제거
    remove_field => ["ecs", "host", "@version", "agent", "log", "tags",  "input", "message"]
  }

  # "date" 필드를 이용하여 Elasticsearch에서 인식할 수 있는 date 타입의 형태로 필드를 추가
  # date {
  #   match => [ "date", "yyyy"]
  #   timezone => "Asia/Seoul"
  #   locale => "ko"
  #   target => "convert_date" # 년월일 표기 타입
  # }

  # Kibana에서 데이터 분석시 필요하기 때문에 숫자 타입으로 변경
  mutate {
    convert => {
      "net_subg" => "float"
      "net_reveg" => "float"
      "movie_reveg" => "float"
      "audience_g" => "float"
    }
    remove_field => [ "@timestamp" ]
  }
}

output {

  # 콘솔창에 어떤 데이터들로 필터링 되었는지 확인
  stdout {
          codec => rubydebug
  }

  # 위에서 설치한 Elasticsearch 로 "covid-19" 라는 이름으로 인덱싱 
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "ratio_nm"
  }
}